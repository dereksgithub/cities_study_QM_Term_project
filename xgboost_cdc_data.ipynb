{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cdc_regression_drop, cdc_regression['Coronary_heart_disease_among_adults_aged_GE18_years'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data into DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Calculate the root mean squared error\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for actual values\n",
    "plt.scatter(y_test.index, y_test, color='blue', label='Actual Values')\n",
    "\n",
    "# Scatter plot for predicted values\n",
    "plt.scatter(y_test.index, y_pred, color='red', alpha=0.5, label='Predicted Values')\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict = xgb_model.get_score(importance_type='weight')\n",
    "importances = [importance_dict.get(f, 0.) for f in cdc_regression.columns]\n",
    "\n",
    "# Create a series for visualization\n",
    "importance_series = pd.Series(importances, index=cdc_regression.columns)\n",
    "\n",
    "# Sort the feature importances\n",
    "sorted_importances = importance_series.sort_values(ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "sorted_importances.plot(kind='bar')\n",
    "plt.title('Feature Importances in XGBoost Model')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
